{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "input_dim = x_train[0].shape[0] #num of predictor variables learning_rate = 1e-5\n",
    "input_layer = Input(shape=(input_dim, ), name=”input”)\n",
    "#Input Layer\n",
    "encoder = Dense (2000, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "#Encoder’s first dense layer\n",
    "encoder = Dense (1000, activation=”relu”,\n",
    "activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "#Encoder’s second dense layer\n",
    "encoder = Dense (500, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Code layer\n",
    "encoder = Dense (200, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoder’s first dense layer\n",
    "decoder = Dense(500, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(encoder)\n",
    "# Decoder’s second dense layer\n",
    "decoder = Dense(1000, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Decoder’s Third dense layer\n",
    "decoder = Dense(2000, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(decoder)\n",
    "# Output Layer\n",
    "decoder = Dense(input_dim, activation=”sigmoid”, activity_regularizer=regularizers.l1(learning_rate))(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_1 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_1.compile(metrics=[‘accuracy’],loss=’mean_squared_error’,optimizer=’adam’)\n",
    "satck_1 = autoencoder_1.fit(x_train, x_train,epochs=200,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2_input = autoencoder_1.predict(x_train)\n",
    "autoencoder_2_input = np.concatenate((autoencoder_2_input , x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_2.compile(metrics=[‘accuracy’],loss=’mean_squared_error’,optimizer=’adam’)\n",
    "satck_2 = autoencoder_2.fit(autoencoder_2_input, autoencoder_2_input,epochs=100,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_3_input = autoencoder_2.predict(autoencoder_2_input)\n",
    "autoencoder_3_input = np.concatenate((autoencoder_3_input, autoencoder_2_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2 = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder_3.compile(metrics=[‘accuracy’], loss=’mean_squared_error’, optimizer=’adam’)\n",
    "satck_3 = autoencoder_3.fit(autoencoder_3_input, autoencoder_3_input, epochs=50, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
